# Gobuster
Después de descubrir una aplicación web, siempre vale la pena verificar si podemos descubrir archivos o directorios ocultos en el servidor web que no estén destinados al acceso público.
Podemos utilizar herramientas como ffuf o GoBuster para realizar la enumeración de directorios "directory enumeration". 

## Directory/File Enumeration
GoBuster es una herramienta versátil que permite realizar ataques de fuerza bruta a **DNS**, **vhost** y **directorios**.

La herramienta tambien cuenta com adicionales funcionalidades para enumeración de AWS S3 buckets. 

```shell-session
gobuster dir -u http://10.10.10.121/ -w /usr/share/seclists/Discovery/Web-Content/common.txt
```

![[img/20250313212859.png]]

## DNS Subdomain Enumeration
También puede haber recursos esenciales alojados en subdominios, como paneles de administración o aplicaciones con funcionalidad adicional que podrían ser explotados.

Podemos usar GoBuster para enumerar los subdominios disponibles de un dominio determinado usando el indicador dns para especificar el modo DNS.

### Install SecLists

```shell-session
 git clone https://github.com/danielmiessler/SecLists
```

o mas rápido 
```shell-session
 sudo apt install seclists -y
```

A continuación, agregue un servidor DNS como 1.1.1.1 al archivo /etc/resolv.conf

```shell-session
gobuster dns -d inlanefreight.com -w /usr/share/SecLists/Discovery/DNS/namelist.txt
```
![[Pasted image 20250313220448.png]]

## Web Enumeration Tips
Repasemos algunos consejos de enumeración web adicionales que ayudarán a completar las máquinas en HTB y en el mundo real.

### Banner Grabbing / Web Server Headers
Los encabezados de un servidor web ofrecen una buena visión de lo que está alojado en un servidor web.

```shell-session
curl -IL https://www.inlanefreight.com
```
![[Pasted image 20250313222927.png]]

### Whatweb
```shell-session
 whatweb 10.10.10.121
```
![[Pasted image 20250313223043.png]]

```shell-session
whatweb --no-errors 10.10.10.0/24
```
![[Pasted image 20250313223113.png]]

### Certificados
Los certificados SSL/TLS son otra fuente de información potencialmente valiosa si se utiliza HTTPS. Navegación.
![[Pasted image 20250313223507.png]]
### Robots.txt
Es común que los sitios web contengan un archivo robots.txt, cuyo propósito es indicar a los rastreadores de motores de búsqueda como Googlebot qué recursos pueden y no pueden acceder para indexar.

El archivo robots.txt puede proporcionar información valiosa, como la ubicación de archivos privados y páginas de administración. En este caso, vemos que el archivo robots.txt contiene dos entradas no permitidas.
![[Pasted image 20250313223949.png]]
Al navegar a http://10.10.10.121/private en un navegador, se revela una página de inicio de sesión de administrador de HTB.

### Source Code
También vale la pena revisar el código fuente de cualquier página web que encontremos.

![[Pasted image 20250313224452.png]]